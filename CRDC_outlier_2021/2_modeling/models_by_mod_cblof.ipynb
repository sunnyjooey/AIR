{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import operator\n",
    "import functools\n",
    "import json\n",
    "import pickle\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "dat_dir = 'I:/NCES/NCES_Dev/sunjoo_LEE_MOVE/CRDC_outlier_2021_2/0_processed_data/'\n",
    "the_data_file = '{}crdc_prepped_formod.csv'.format(dat_dir)\n",
    "dfa = pd.read_csv(the_data_file, dtype={'combokey':str, 'leaid':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# module: columns in module\n",
    "with open('{}mod_col.txt'.format(dat_dir), 'rb') as handle:\n",
    "    new_mod_dict = json.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models import cblof\n",
    "from keras import losses\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in param_grid_all\n",
    "import param_raw\n",
    "\n",
    "param_grid = {}\n",
    "\n",
    "# classifiers\n",
    "clfs = {'CBLOF': cblof.CBLOF()}\n",
    "\n",
    "# only these classifiers in this notebook\n",
    "clf_this_nb = ['CBLOF']\n",
    "for c in clf_this_nb:\n",
    "    param_grid[c] = param_raw.param_grid_all[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of params to go through and update during modeling -- this has all the specifications for each model!\n",
    "all_clf_mods = []\n",
    "for clf_name in clf_this_nb:\n",
    "    parameter_values = param_grid[clf_name] #creates a set of params for each combination in hyper-param lists\n",
    "    for p in ParameterGrid(parameter_values):\n",
    "        seed = random.randint(0, 1000000)\n",
    "        clf_param_id = clf_name + '_' + str(seed)\n",
    "        clf_param_info = {clf_param_id: {}} #create dictionary to keep track of everything about the clf and particular params\n",
    "        clf_param_info[clf_param_id]['params'] = p\n",
    "        clf_param_info[clf_param_id]['clf'] = clf_name\n",
    "        clf_param_info[clf_param_id]['seed'] = seed\n",
    "        clf_param_info[clf_param_id]['modules_done'] = []\n",
    "        clf_param_info[clf_param_id]['ten_fold_done'] = 0\n",
    "        all_clf_mods.append(clf_param_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_dir = 'I:/NCES/NCES_Dev/sunjoo_LEE_MOVE/CRDC_outlier_2021_2/2_modeling/'\n",
    "\n",
    "if not os.path.isdir('{}models/'.format(mod_dir)):\n",
    "    os.mkdir('{}models/'.format(mod_dir))\n",
    "    print('Made models dir')\n",
    "\n",
    "if not os.path.isdir('{}results/'.format(mod_dir)):\n",
    "    os.mkdir('{}results/'.format(mod_dir))    \n",
    "    print('Made results dir')\n",
    "\n",
    "# this is to prevent accidentally overwriting models list -- manually go and delete it first if you want to replace it\n",
    "if not os.path.isfile('{}models/all_clf_mods_bymod.pickle'.format(mod_dir)):    \n",
    "    with open('{}models/all_clf_mods_bymod.pickle'.format(mod_dir), 'wb') as handle:\n",
    "        pickle.dump(all_clf_mods, handle)\n",
    "    print('Saved all model specs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# do not transform ratios and indicators\n",
    "cols = dfa.columns\n",
    "all_transform_cols = [col for col in cols if '_ind' not in col and '_ratio' not in col and '_mean' not in col and col!='pov_per_5-17']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights for some variables\n",
    "hs_15 = ['sch_grade_09', 'sch_grade_10', 'sch_grade_11', 'sch_grade_12', 'sch_ugdetail_hs'] #each 1.15 weight\n",
    "stat_20 = ['sch_status_sped','sch_status_charter','sch_status_magnet', 'sch_altfocus_pre_mean'] #each 1.2 weight\n",
    "imp_25 = ['sch_grade_ps','sch_altfocus_post_mean','tot_enrl','pov_per_5-17'] #each 1.25 weight\n",
    "d1 = {key:1.15 for key in hs_15}\n",
    "d2 = {key:1.2 for key in stat_20}\n",
    "d3 = {key:1.25 for key in imp_25}\n",
    "col_weights = {**d1, **d2, **d3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CBLOF_50035\n",
      "\n",
      "NO PSCH\n",
      "Initialized  CBLOF_50035 NO PSCH with 0s\n",
      "Cols to run length: 815\n",
      "Running CBLOF_50035 NO PSCH 1\n",
      "Cluster sizes: [3588, 523, 43822, 865, 1923, 97, 4322, 4, 389, 13, 3, 261, 2350, 298, 60, 23102, 11, 511, 172, 5544]\n",
      "Running CBLOF_50035 NO PSCH 2\n",
      "Cluster sizes: [18138, 16, 3, 509, 90, 994, 37775, 2, 95, 2100, 239, 6108, 7589, 6, 237, 983, 3313, 399, 8132, 1147]\n",
      "Running CBLOF_50035 NO PSCH 3\n",
      "Cluster sizes: [7355, 2570, 189, 22287, 151, 3637, 43463, 3, 289, 129, 42, 2603, 1110, 1471, 258, 254, 1, 257, 18, 1790]\n",
      "Running CBLOF_50035 NO PSCH 4\n"
     ]
    }
   ],
   "source": [
    "# reopen to pick up where you left off\n",
    "with open('{}models/all_clf_mods_bymod.pickle'.format(mod_dir), 'rb') as handle:\n",
    "    all_clf_mods = pickle.load(handle)\n",
    "    \n",
    "# run, baby, run\n",
    "for clf_i, mod_dict in enumerate(all_clf_mods): #this is a list of dictionaries\n",
    "    for clf_param_id, info_dict in mod_dict.items(): #there is only one\n",
    "        if len(info_dict['modules_done']) == len(new_mod_dict): #this classifier with params is already done\n",
    "            continue\n",
    "            \n",
    "        else:\n",
    "            print('')\n",
    "            print(clf_param_id)\n",
    "            clf_name = info_dict['clf'] #COPOD\n",
    "            p = info_dict['params'] #dict of params\n",
    "            clf = clfs[clf_name] #base classifier\n",
    "            # set params for classifier\n",
    "            clf.set_params(**p)\n",
    "            if clf_name in ['CBLOF','IForest','AUTO_ENC']:\n",
    "                clf.set_params(random_state=info_dict['seed']) #use same seed\n",
    "                if clf_name == 'CBLOF':\t\n",
    "                    #set params for KMeans in CBLOF (doesn't seem to happen automatically)\t\n",
    "                    clf.clustering_estimator.set_params(**{'n_clusters': info_dict['params']['n_clusters'], 'random_state':info_dict['seed']})\t\n",
    "\n",
    "            \n",
    "            # check if this is a new model with no runs -- make new df_scores\n",
    "            if (len(info_dict['modules_done']) == 0) and (info_dict['ten_fold_done'] == 0):\n",
    "                df_scores = pd.DataFrame()\n",
    "                print('Made new df_scores for', clf_param_id)\n",
    "\n",
    "            # otherwise add to old dataframe\n",
    "            else:\n",
    "                df_scores = pd.read_csv('{}results/df_scores_{}.csv'.format(mod_dir, clf_param_id))\n",
    "            \n",
    "            # subset to only modules not run yet\n",
    "            modules_to_run = [m for m in new_mod_dict.keys() if m not in info_dict['modules_done']]\n",
    "            \n",
    "            for mod in modules_to_run:\n",
    "                print('')\n",
    "                print('NO', mod)\n",
    "                \n",
    "                # read-in data\n",
    "                dfa = pd.read_csv(the_data_file, dtype={'combokey':str, 'leaid':str})\n",
    "                ids = dfa.iloc[:,:2] # index, school and lea id\n",
    "                dfa = dfa.iloc[:,2:] # just data\n",
    "                new_col = dfa.columns # all cols in new data (aggregated cols)\n",
    "\n",
    "                # if first of 10, initialize all rows to 0\n",
    "                if info_dict['ten_fold_done'] == 0:\n",
    "                    df_scores['NO-'+ mod] = [0] * dfa.shape[0]\n",
    "                    print('Initialized ', clf_param_id, 'NO', mod, 'with 0s')\n",
    "                \n",
    "                # take out columns for one module\n",
    "                cols_in_mod = new_mod_dict[mod]\n",
    "                cols_to_run = [c for c in dfa.columns if c not in cols_in_mod]\n",
    "                \n",
    "                df = dfa[cols_to_run]\n",
    "                print('Cols to run length:', len(cols_to_run))\n",
    "                del dfa\n",
    "\n",
    "                # divide into 10\n",
    "                random.seed(info_dict['seed'])\n",
    "                samp = [random.randint(1,10) for x in range(df.shape[0])]\n",
    "                \n",
    "                # already done i\n",
    "                done_i = info_dict['ten_fold_done']\n",
    "                for i in range(done_i+1, 11):\n",
    "                    print('Running', clf_param_id, 'NO', mod, i)\n",
    "                    # divide into training and testing\n",
    "                    idx = [ii for ii,e in enumerate(samp) if e!=i]\n",
    "                    idx_t = [ii for ii in range(df.shape[0]) if ii not in idx]\n",
    "                    \n",
    "                    # get cols to transform\n",
    "                    transform_cols = [col for col in df.columns if col in all_transform_cols]\n",
    "                    col_transformer = ColumnTransformer(\n",
    "                        transformers=[('ss', StandardScaler(), transform_cols)],\n",
    "                        remainder='passthrough',\n",
    "                        transformer_weights=col_weights\n",
    "                        )\n",
    "                    \n",
    "                    # train on 9/10, fit on 1/10\n",
    "                    X_train = df.iloc[idx,:]\n",
    "                    X_train_transformed = col_transformer.fit_transform(X_train)\n",
    "                    del X_train\n",
    "                    X_test = df.iloc[idx_t,:]\n",
    "                    X_test_transformed = col_transformer.transform(X_test)\n",
    "                    del X_test\n",
    "                    # train\n",
    "                    clf.fit(X_train_transformed)\n",
    "\n",
    "                    # get outlier scores for last tenth of data\n",
    "                    y_test_scores = clf.decision_function(X_test_transformed)  # outlier scores\n",
    "                    df_scores.iloc[idx_t, df_scores.shape[1]-1] = y_test_scores\n",
    "\n",
    "                    # save outlier scores\n",
    "                    df_scores.to_csv('{}results/df_scores_{}.csv'.format(mod_dir, clf_param_id), index=False)\n",
    "\n",
    "                    # save modeling done - i\n",
    "                    info_dict['ten_fold_done'] = i\n",
    "                    \n",
    "                    if clf_name == 'CBLOF':\n",
    "                        print('Cluster sizes:', list(clf.cluster_sizes_))\n",
    "                        \n",
    "                        if 'inertia' in info_dict.keys():\n",
    "                            info_dict['inertia'].append(clf.clustering_estimator_.inertia_)\n",
    "                        else:\n",
    "                            info_dict['inertia'] = [clf.clustering_estimator_.inertia_]\n",
    "                    \n",
    "                    if i == 10:\n",
    "                        # save modeling done - mod\n",
    "                        info_dict['modules_done'].append(mod)\n",
    "                        info_dict['ten_fold_done'] = 0\n",
    "\n",
    "                    \n",
    "                    all_clf_mods[clf_i] = {clf_param_id: info_dict}\n",
    "                    with open('{}models/all_clf_mods_bymod.pickle'.format(mod_dir),'wb') as handle:\n",
    "                        pickle.dump(all_clf_mods, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
