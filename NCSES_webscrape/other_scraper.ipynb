{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9cc85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### contains the code for scraping\n",
    "### Legacy Publications non-archived OTH/WP/WS/WEB content types\n",
    "### excluding pdf and excel direct downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "47800b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pickle as pkl\n",
    "\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b4b91a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input content file\n",
    "CONTENT_FILE = '/Users/sjlee/Documents/github/ncses_data/2022-06-29-prod-cms-content.xlsx'\n",
    "content = pd.read_excel(CONTENT_FILE, sheet_name='Legacy Publications')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "fd3ebcf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sjlee/opt/anaconda3/envs/my_env/lib/python3.7/site-packages/pandas/core/indexing.py:1667: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = value\n"
     ]
    }
   ],
   "source": [
    "# filter to just the urls that need to be coded\n",
    "other = content[(content['Archived']=='N') & (content['Type'].isin(['OTH', 'WP', 'WS', 'WEB']))]\n",
    "oth = other.drop_duplicates(['URL'])\n",
    "oth.loc[:,'xls'] = oth['URL'].apply(lambda x: bool(re.search('.xlsx|.xls', x)))\n",
    "oth.loc[:,'pdf'] = oth['URL'].apply(lambda x: bool(re.search('.pdf', x)))\n",
    "web = oth[(~oth['xls']) & (~oth['pdf'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84806790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "583             https://www.nsf.gov/statistics/profiles/\n",
       "659               https://www.nsf.gov/statistics/states/\n",
       "711    https://www.nsf.gov/statistics/seind14/index.c...\n",
       "765      https://www.nsf.gov/statistics/2015/ncses15201/\n",
       "768      https://www.nsf.gov/statistics/2015/ncses15200/\n",
       "792      https://www.nsf.gov/statistics/2016/ncses16200/\n",
       "844              https://www.nsf.gov/statistics/randdef/\n",
       "891        https://www.nsf.gov/statistics/2020/nsf20304/\n",
       "900        https://www.nsf.gov/statistics/2020/nsf20310/\n",
       "903        https://www.nsf.gov/statistics/2020/nsf20313/\n",
       "908        https://www.nsf.gov/statistics/2020/nsf20315/\n",
       "911            https://www.nsf.gov/statistics/ffrdclist/\n",
       "912      https://www.nsf.gov/statistics/2021/ncses21200/\n",
       "913      https://www.nsf.gov/statistics/2021/ncses21201/\n",
       "914      https://www.nsf.gov/statistics/2021/ncses21202/\n",
       "918      https://www.nsf.gov/statistics/2022/ncses22205/\n",
       "Name: URL, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web['URL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c5a5589",
   "metadata": {},
   "outputs": [],
   "source": [
    "### note: url for text and page are different\n",
    "def page_with_tabs(soup, row):\n",
    "    url_base = 'https://www.nsf.gov'\n",
    "    \n",
    "    # text for page\n",
    "    legacy = 'Y'\n",
    "    pub_type = row['Type']\n",
    "    asset_type = 'page'\n",
    "    pub_date = row['Publish Date']\n",
    "    pub_id = row['Legacy Pub ID']\n",
    "    slug_path = pub_id\n",
    "    page_title = soup.find_all('h1')[-1].text\n",
    "    url_link = row['URL']\n",
    "    page_text = soup.find_all('div', class_='col-sm-12')[1].find_all('p', class_=False)[0].text\n",
    "    return_lst = [[legacy, pub_type, asset_type, pub_date, pub_id, slug_path, page_title, url_link, page_text]]\n",
    "    \n",
    "    # get tabs\n",
    "    tabs = soup.select('.tabs')[0].find_all(\"li\")\n",
    "    hrefs = [(t.text, t.find('a').get('data-hash-id'), t.find('a').get('href')) for t in tabs]\n",
    "    for (title, sec_id, href) in hrefs:\n",
    "        tab_url = url_base + href\n",
    "        tab_page = requests.get(tab_url)\n",
    "        tab_soup = BeautifulSoup(tab_page.content, \"html.parser\")\n",
    "        \n",
    "        tab_slug_path = str(slug_path) + '->' + title.replace(' ', '-').lower()\n",
    "        para = tab_soup.find_all('p')\n",
    "        if len(para) > 0:\n",
    "            text = ' '.join([p.text for p in para])\n",
    "        else:\n",
    "            text = ''\n",
    "        one_lst = [legacy, pub_type, 'text', pub_date, pub_id, tab_slug_path, title, tab_url, text]\n",
    "        return_lst.append(one_lst)\n",
    "    \n",
    "    return return_lst\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ed17df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_with_panels(soup, row):\n",
    "    url_base = 'https://www.nsf.gov'\n",
    "    \n",
    "    # text for page\n",
    "    legacy = 'Y'\n",
    "    pub_type = row['Type']\n",
    "    asset_type = 'page'\n",
    "    pub_date = row['Publish Date']\n",
    "    pub_id = row['Legacy Pub ID']\n",
    "    slug_path = pub_id\n",
    "    page_title = soup.find_all('h1')[-1].text\n",
    "    url_link = row['URL']\n",
    "    page_text = ''\n",
    "    return_lst = [[legacy, pub_type, asset_type, pub_date, pub_id, slug_path, page_title, url_link, page_text]]\n",
    "    \n",
    "    # get tabs\n",
    "    tabs = soup.find('div', id='publication-tab').select('.dst-chapter')\n",
    "    hrefs = [(t.text.strip(), t.get('data-hash-id'), t.find('a').get('href')) for t in tabs]\n",
    "    for (title, sec_id, href) in hrefs:\n",
    "        tab_url = url_base + href\n",
    "        tab_page = requests.get(tab_url)\n",
    "        tab_soup = BeautifulSoup(tab_page.content, \"html.parser\")\n",
    "        \n",
    "        tab_slug_path = str(slug_path) + '->' + title.replace(' ', '-').lower()\n",
    "        para = tab_soup.find_all('p')\n",
    "        if len(para) > 0:\n",
    "            text = ' '.join([p.text for p in para])\n",
    "        else:\n",
    "            text = ''\n",
    "        one_lst = [legacy, pub_type, 'text', pub_date, pub_id, tab_slug_path, title, tab_url, text]\n",
    "        return_lst.append(one_lst)\n",
    "    \n",
    "    return return_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7955ea0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_with_asset(soup, row):\n",
    "    url_base = 'https://www.nsf.gov'\n",
    "   \n",
    "    # for page\n",
    "    legacy = 'Y'\n",
    "    pub_type = row['Type']\n",
    "    pub_date = row['Publish Date']\n",
    "    pub_id = row['Legacy Pub ID']\n",
    "    slug_path = pub_id\n",
    "    title = soup.find_all('h1')[-1].text\n",
    "    \n",
    "    url = row['URL']\n",
    "    return_lst = []\n",
    "    \n",
    "    # content soup\n",
    "    url_tail = soup.find('article').find('a').get('href')\n",
    "    content_url = url_base + url_tail\n",
    "    content_page = requests.get(content_url)\n",
    "    content_soup = BeautifulSoup(content_page.content, \"html.parser\")\n",
    "    \n",
    "    # figure\n",
    "    fig_title = content_soup.find('figcaption').text\n",
    "    fig_title = re.sub('FIGURE [0-9]{1,3}. ', '', fig_title)\n",
    "    source_tail = content_soup.find('a', class_='source-data').get('href')\n",
    "    fig_url = url + source_tail\n",
    "    fig_lst = [legacy, pub_type, 'figure', pub_date, pub_id, slug_path, fig_title, fig_url, '']\n",
    "    return_lst.append(fig_lst)\n",
    "\n",
    "    # text\n",
    "    ps = content_soup.find('a', class_='source-data').find_all_next(\"p\")\n",
    "    text = ' '.join([p.text for p in ps if p.find('a')==None])\n",
    "    text_lst = [legacy, pub_type, 'text', pub_date, pub_id, slug_path, title, url, text]\n",
    "    return_lst.append(text_lst)\n",
    "    \n",
    "    return return_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e60948c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.nsf.gov/statistics/profiles/\n",
      "https://www.nsf.gov/statistics/states/\n",
      "https://www.nsf.gov/statistics/seind14/index.cfm/state-data\n",
      "https://www.nsf.gov/statistics/2015/ncses15201/\n",
      "https://www.nsf.gov/statistics/2015/ncses15200/\n",
      "https://www.nsf.gov/statistics/2016/ncses16200/\n",
      "https://www.nsf.gov/statistics/randdef/\n",
      "https://www.nsf.gov/statistics/2020/nsf20304/\n",
      "https://www.nsf.gov/statistics/2020/nsf20310/\n",
      "https://www.nsf.gov/statistics/2020/nsf20313/\n",
      "https://www.nsf.gov/statistics/2020/nsf20315/\n",
      "https://www.nsf.gov/statistics/ffrdclist/\n",
      "https://www.nsf.gov/statistics/2021/ncses21200/\n",
      "https://www.nsf.gov/statistics/2021/ncses21201/\n",
      "https://www.nsf.gov/statistics/2021/ncses21202/\n",
      "https://www.nsf.gov/statistics/2022/ncses22205/\n"
     ]
    }
   ],
   "source": [
    "archived = []\n",
    "error = []\n",
    "done = []\n",
    "skip = []\n",
    "\n",
    "cols = ['Legacy', 'Pub Type', 'Asset Type', 'Publish Date', 'Pub ID', 'Path', 'Title', 'URL', 'Text']\n",
    "parsed_lst = []\n",
    "\n",
    "for i, row in web.iterrows():\n",
    "    url = row['URL']\n",
    "    print(url)\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    if bool(re.search('online archive', soup.text)):\n",
    "        archived.append(url)\n",
    "    elif re.search('offline', soup.text):\n",
    "        error.append(url)\n",
    "    else: \n",
    "        if bool(re.search('states', url)):\n",
    "            return_lst = page_with_tabs(soup, row)\n",
    "            parsed_lst.extend(return_lst)\n",
    "            done.append(url)\n",
    "        \n",
    "        else:\n",
    "            tabs = soup.find('div', id='publication-tab')\n",
    "            if tabs != None:\n",
    "                if len(tabs) > 3:\n",
    "                    return_lst = page_with_panels(soup, row)\n",
    "                    parsed_lst.extend(return_lst)\n",
    "                    done.append(url)\n",
    "                else:\n",
    "                    try:\n",
    "                        return_lst = page_with_asset(soup, row)\n",
    "                        parsed_lst.extend(return_lst)\n",
    "                        done.append(url)\n",
    "                    except:\n",
    "                        skip.append(url)\n",
    "            else:\n",
    "                skip.append(url)\n",
    "\n",
    "df = pd.DataFrame(parsed_lst, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "588a8faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(parsed_lst, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "76954d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "assets = df.groupby('Asset Type').size()\n",
    "nums = {'Text': assets.text, \n",
    " 'Figure': assets.figure, \n",
    " 'Table': 0, \n",
    " 'Page': assets.page, \n",
    " 'Error': len(error), \n",
    " 'Archived': len(archived), \n",
    " 'Irregular': len(skip), \n",
    " 'Zip': 0, \n",
    " 'PDF': oth[oth['pdf']].shape[0], \n",
    " 'Excel': oth[oth['xls']].shape[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "38343103",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/sjlee/Documents/github/ncses_data/legacy_other.pkl', 'wb') as f:\n",
    "    pkl.dump(df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b557a3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/sjlee/Documents/github/ncses_data/legacy_other_nums.pkl', 'wb') as f:\n",
    "    pkl.dump(nums, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b18db1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
