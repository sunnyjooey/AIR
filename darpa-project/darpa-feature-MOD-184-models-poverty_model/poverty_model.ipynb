{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monitoring System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "\n",
    "1. **Task Orchestration**\n",
    "    1. Dependency resolution\n",
    "    1. Job scheduling\n",
    "    1. Container/server execution    \n",
    "1. **Input/Output Pipeline**\n",
    "    1. Data Warehouse (predictors)\n",
    "    1. Dashboard (model output)\n",
    "1. **Model Description**\n",
    "    1. Indicator definition\n",
    "    1. Training/Survey dataset\n",
    "    1. Model structure\n",
    "1. **Modeling Outlook**\n",
    "    1. Training/Survey Dataset\n",
    "    1. Predictor Dataset\n",
    "    1. ANN Advances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "from itertools import product\n",
    "from urllib.parse import urlparse\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "from IPython.display import SVG\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import model_to_dot\n",
    "import geopandas as gpd\n",
    "import geoviews as gv\n",
    "import geoviews.tile_sources as gts\n",
    "import holoviews as hv\n",
    "import hvplot.pandas\n",
    "import hvplot.xarray\n",
    "import luigi\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import panel as pn\n",
    "import param\n",
    "import xarray as xr\n",
    "\n",
    "from kidomain.poverty.data import GetPredictors, GuessResponsePixels, GetTrainingData\n",
    "from kidomain.poverty.model import Train, Predict, Output\n",
    "from warehouse import esacci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task Orchestration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The EWS data and models as installable Python packages\n",
    "- All data processing and modeling steps are linked \"Tasks\"\n",
    "- A cloud-based scheduler resolves task dependencies and executes task in Docker containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import luigi\n",
    "from kidomain.poverty.model import Output\n",
    "\n",
    "task = Output.from_str_params({\n",
    "    \"fgt_a\": 0,\n",
    "    \"admin_level\": 1,\n",
    "    \"threshold\": 0.7,\n",
    "    \"period\": \"2011-01-01-2017-12-31\"\n",
    "})\n",
    "\n",
    "luigi.build([task], local_scheduler=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input/Output Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input**\n",
    "\n",
    "- Warehouse of remote sensing data\n",
    "- Easy to update by changing task parameter\n",
    "- Standardized format as Cloud Optimized GeoTIFF (COG), but otherwise \"raw\" data\n",
    "- Ready to catalog and query with Spatio-Temporal Asset Catalogs (STACs) and sat-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = esacci.MigrateToWarehouse()\n",
    "task.input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictors(param.Parameterized):\n",
    "    \n",
    "    _task = dict(GetPredictors.get_params())\n",
    "    period = param.CalendarDate(\n",
    "        default=_task[\"period\"]._default.date_a,\n",
    "        bounds=(\n",
    "            _task[\"period\"]._default.date_a,\n",
    "            _task[\"period\"]._default.date_b,\n",
    "            )\n",
    "        )\n",
    "    variable = param.ObjectSelector(\n",
    "        default=next(iter(_task[\"predictors\"]._default.keys())),\n",
    "        objects=_task[\"predictors\"]._default.keys(),\n",
    "        )\n",
    "    band = param.ObjectSelector(\n",
    "        default=1,\n",
    "        objects=[1],\n",
    "    )\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.da = None\n",
    "        self.read()\n",
    "    \n",
    "    @param.depends(\"period\", \"variable\", watch=True)\n",
    "    def read(self):\n",
    "        \n",
    "        task = GetPredictors(period=self.period)        \n",
    "        with task.output().open() as f:\n",
    "            da = f.read()\n",
    "        da = da.sel(var=(self.variable,), drop=True)\n",
    "        if self.variable == \"landscan\":\n",
    "            da = np.log(da.where(da > 0))\n",
    "            da.attrs[\"cmap\"] = \"viridis\"\n",
    "        elif self.variable == \"svdnb\":\n",
    "            da = np.log(da.where(da > 0))\n",
    "            da.attrs[\"cmap\"] = \"gray\"\n",
    "        self.da = da\n",
    "\n",
    "        self.band = 1\n",
    "        self.param[\"band\"].objects = da[\"band\"].data.tolist()\n",
    "    \n",
    "    def view(self):\n",
    "        \n",
    "        da = self.da.sel(band=self.band, drop=True)\n",
    "        plt = da.hvplot(\n",
    "            x=\"lon\", y=\"lat\", rasterize=True, geo=True, cmap=da.attrs.get(\"cmap\"),\n",
    "            xlabel=\"Longitude\",\n",
    "            ylabel=\"Latitude\",\n",
    "            )\n",
    "        \n",
    "        return plt\n",
    "\n",
    "predictors = Predictors(variable=\"landscan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.Row(\n",
    "    pn.Param(predictors.param, widgets={\"period\": pn.widgets.DatePicker}),\n",
    "    predictors.view,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Output**\n",
    "\n",
    "- Gridded and aggregated to administrative boundaries\n",
    "- Self-describing JSON (incorporating GeoJSON)\n",
    "- HoloViews ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = Predict.from_str_params({\"period\": \"2016-12-01\"})\n",
    "target = task.output()[\"FGT_0\"]\n",
    "da = xr.open_rasterio(target.path).sel(band=1).drop(\"band\")\n",
    "\n",
    "da.hvplot(\n",
    "    geo=True, rasterize=True, dynamic=False,\n",
    "    xlabel=\"Longitude\", ylabel=\"Latitude\", clabel=\"FGT(a=0)\",\n",
    "    cmap=\"bkr\", title=f\"Gridded Output: 2016-12-01\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predict(param.Parameterized):\n",
    "    \n",
    "    admin_level = param.ObjectSelector(\n",
    "        default=1,\n",
    "        objects=[1, 2, 3],\n",
    "        )\n",
    "    location = param.ObjectSelector(allow_None=True)\n",
    "    period = param.CalendarDate()\n",
    "    fgt_a = param.Integer(\n",
    "        default=1,\n",
    "        bounds=(0, 1),\n",
    "        label=\"FGT \\\"a\\\" Parameter\",\n",
    "        )\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.gdf = None\n",
    "        self.hover_cols = None\n",
    "        self.da = None\n",
    "        self.read()\n",
    "\n",
    "    @param.depends(\"admin_level\", \"fgt_a\", watch=True)\n",
    "    def read(self):\n",
    "        \n",
    "        task = Output.from_str_params({\n",
    "            \"admin_level\": self.admin_level,\n",
    "            \"fgt_a\": self.fgt_a,\n",
    "            \"period\": \"2011-01-01-2017-12-31\",\n",
    "            \"threshold\": 0.7,\n",
    "            })\n",
    "        with task.output().open() as f:\n",
    "            dd = json.load(f)\n",
    "            \n",
    "        # store location as instance attribute\n",
    "        location = dd[\"coords\"].pop(\"location\")\n",
    "        # FIXME upstream: have a location \"@id\" relative to a \"@context.@base\"\n",
    "        dd[\"@context\"] = {\n",
    "            \"@base\": \"s3://\" + urlparse(location[\"@id\"]).hostname.split(\".\")[0]\n",
    "        }\n",
    "        location[\"@id\"] = urlparse(location[\"@id\"]).path\n",
    "        gdf = gpd.read_file(dd[\"@context\"][\"@base\"] + location[\"@id\"])\n",
    "        gdf = gdf.set_index(\"id\")\n",
    "        hover_cols = gdf.columns.str.endswith(\"_NAME\")\n",
    "        loc = gdf.loc[:, hover_cols].isnull()\n",
    "        for _loc in loc:\n",
    "            gdf.loc[loc[_loc], _loc] = \"\"\n",
    "        self.gdf = gdf\n",
    "        self.hover_cols = gdf.columns[hover_cols].tolist()\n",
    "        \n",
    "        self.location = None\n",
    "        self.param[\"location\"].objects = gdf.index.values.tolist()\n",
    "        \n",
    "        # store timeseries data as instance attribute, and update parameter\n",
    "        period = dd[\"coords\"].pop(\"period\")\n",
    "        period = [pd.Period(p).to_timestamp().date() for p in period[\"data\"]]\n",
    "\n",
    "        self.period = period[0]\n",
    "        self.param[\"period\"].bounds = (period[0], period[-1])\n",
    "\n",
    "        da = xr.DataArray.from_dict(dd)\n",
    "        da[\"location\"] = gdf.index.values\n",
    "        da[\"period\"] = period\n",
    "        self.da = da\n",
    "        \n",
    "    def view_map(self):\n",
    "\n",
    "        self.gdf[\"FGT\"] = self.da.sel(period=self.period, drop=True)\n",
    "        plt = self.gdf.hvplot(\n",
    "            c=\"FGT\", hover_cols=self.hover_cols,\n",
    "            geo=True, tiles=\"CartoLight\",\n",
    "            xlabel=\"Longitude\", ylabel=\"Latitude\", clabel=\"FGT\",\n",
    "        )\n",
    "\n",
    "        return plt\n",
    "    \n",
    "    def view_ts(self):\n",
    "        \n",
    "        location = self.location\n",
    "        if not location:\n",
    "            location = self.da[\"location\"][0]\n",
    "        da = self.da.sel(location=location, drop=True)\n",
    "        plt = da.hvplot(xlabel=\"Month\", ylabel=\"FGT\")\n",
    "        \n",
    "        return plt\n",
    "\n",
    "predict = Predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.Column(\n",
    "    pn.Row(\n",
    "        pn.Param(predict.param, widgets={\"period\": pn.widgets.DatePicker}),\n",
    "        predict.view_map,\n",
    "        ),\n",
    "    pn.Row(\n",
    "        predict.view_ts,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Indicator Definition**\n",
    "\n",
    "- Foster-Greer-Thorbecke Index is a headcount value for $a=0$ and a \"gap\" value otherwise\n",
    "- The survey response, in addition to a population weight $w_i$, gives a FGT sample:\n",
    "\n",
    "$$\n",
    "y_i = \\max\\left(0, \\frac{z_{s, t} - e_i}{z_{s,t}}\\right)^a\n",
    "$$\n",
    "\n",
    "- The point-in-time averages make up the training data:\n",
    "\n",
    "$$\n",
    "y_{s, t} = \\sum_{i \\in {s, t}} w_i y_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = GetTrainingData()\n",
    "target = task.output()\n",
    "with target.open() as f:\n",
    "    ds = f.read()\n",
    "\n",
    "#ds = ds.sortby(\"lat\", ascending=False)\n",
    "ds = ds.drop_dims(\"var\")\n",
    "ds_flat = ds.reset_index(\"location\").stack(sample=[\"location\", \"period\"]).reset_index(\"sample\").dropna(\"sample\")\n",
    "ds_flat.hvplot.hist(\n",
    "    y=\"y0\", bins=25,\n",
    "    title=f\"Training Data Distribution (n={ds_flat.sizes['sample']})\",\n",
    "    xlabel=\"FGT(a=0)\",\n",
    "    ylabel=\"Count\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Response(param.Parameterized):\n",
    "    \n",
    "    _task = GuessResponsePixels()\n",
    "    with _task.input()[\"grid\"].open() as f:\n",
    "        _grid = f.read()\n",
    "    _grid.name = \"grid\"\n",
    "    \n",
    "    with GetTrainingData().output().open() as f:\n",
    "        _target = f.read()\n",
    "    _target = _target.drop_dims(\"var\")\n",
    "    _target[\"period\"] = [\n",
    "        pd.Period(p).to_timestamp().date() for p in _target[\"period\"].data\n",
    "    ]\n",
    "\n",
    "    period = param.ObjectSelector(\n",
    "        default=_target[\"period\"][0].data.item(),\n",
    "        objects=_target[\"period\"].data.tolist(),\n",
    "        )\n",
    "    fgt_a = param.Integer(\n",
    "        default=1,\n",
    "        bounds=(0, 1),\n",
    "        label=\"FGT \\\"a\\\" Parameter\"\n",
    "    )\n",
    "        \n",
    "    def view_map(self):\n",
    "        \n",
    "        ds = self._target.sel(period=self.period)\n",
    "        if self.fgt_a == 0:\n",
    "            da = ds[\"y0\"]\n",
    "        else:\n",
    "            da = ds[\"ya\"]\n",
    "        da = da.unstack(\"location\")\n",
    "        da = xr.merge([da, self._grid])[da.name]\n",
    "        plt = da.hvplot.image(\n",
    "            x=\"lon\", y=\"lat\", rasterize=False, geo=True,\n",
    "            cmap=\"bkr\", tiles=\"CartoLight\",\n",
    "            xlabel=\"Longitude\",\n",
    "            ylabel=\"Latitude\",\n",
    "            title=\"Training Data\",\n",
    "            )\n",
    "        \n",
    "        return plt\n",
    "    \n",
    "    def view_ts(self):\n",
    "        \n",
    "        ds_ts = self._target.groupby(\"period\").mean(...)\n",
    "        ds_ts[\"year\"] = (\n",
    "            \"period\",\n",
    "            [p.year for p in ds_ts[\"period\"].data]\n",
    "            )\n",
    "        ds_ts[\"month\"] = (\n",
    "            \"period\",\n",
    "            [p.month for p in ds_ts[\"period\"].data]\n",
    "            )\n",
    "        ds_ts = ds_ts.drop_vars(\"period\").set_coords([\"year\", \"month\"])\n",
    "        y0 = ds_ts[\"y0\"]\n",
    "        y0[\"a\"] = 0\n",
    "        ya = ds_ts[\"ya\"]\n",
    "        ya[\"a\"] = 1\n",
    "        y = xr.concat([y0, ya], dim=\"period\")\n",
    "        \n",
    "        plt = y.hvplot.scatter(\n",
    "            x=\"month\", by=[\"a\", \"year\"],\n",
    "            xlabel=\"Month\", ylabel=\"FGT\",\n",
    "            title=\"Training Data Pixel Average\",\n",
    "            )\n",
    "        \n",
    "        return plt\n",
    "\n",
    "\n",
    "response = Response()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.Column(\n",
    "    pn.Row(\n",
    "        response.param,\n",
    "        response.view_map,\n",
    "    ),\n",
    "    pn.Row(\n",
    "        response.view_ts,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Model Structure**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = Train()\n",
    "model = load_model(train.output()[\"model\"].path)\n",
    "\n",
    "SVG(model_to_dot(model, show_shapes=True, rankdir=\"LR\").create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Outlook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goodness-of-Fit**\n",
    "\n",
    "- View \"ROC\" for classification accuracy\n",
    "- View residuals for classification and regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task = GetTrainingData()\n",
    "# target = task.output()\n",
    "with open(\"/output/intermediate_targets/poverty/data/GetTrainingDataX/f7f1db7cb2\", \"rb\") as f:\n",
    "    ds = pickle.load(f)\n",
    "\n",
    "ds[\"location\"] = np.arange(ds.sizes[\"location\"])\n",
    "ds = ds.drop_dims(\"var\").stack(sample=[\"period\", \"location\"]).dropna(\"sample\", subset=[\"y0\", \"ya\"])\n",
    "\n",
    "with open(\"/output/y_hat.pickle\", \"rb\") as f:\n",
    "    clsn, rgrn = pickle.load(f)\n",
    "    \n",
    "fp, tp, thr = roc_curve(ds[\"y0\"] == 0, clsn[:, 0])\n",
    "roc = xr.Dataset(\n",
    "    {\"fp\": (\"index\", fp), \"tp\": (\"index\", tp), \"thr\": (\"index\", thr)}\n",
    ")\n",
    "roc.isel(index=slice(1, None, 100)).to_dataframe().hvplot.scatter(\n",
    "    x=\"fp\", y=\"tp\", c=\"thr\", frame_width=300, aspect=1, xlim=[0, 1], ylim=[0, 1], cmap=\"dimgray_r\",\n",
    "    title=\"Accuracy of Binary Classification\", xlabel=\"False Positive Rate\", ylabel=\"True Positive Rate\", clabel=\"Cut-off\",\n",
    "    ) * hv.Slope(1, 0).opts(color=\"black\", line_width=1, line_dash=\"dashed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut = 0.7\n",
    "clsn_adj = clsn.copy()\n",
    "clsn_adj[:, 0] = np.where(clsn[:, 0] <= cut, 0, clsn[:, 0])\n",
    "clsn_max = clsn_adj.argmax(axis=1)\n",
    "\n",
    "ds[\"y0_hat\"] = (\"sample\", np.where(clsn_max == 2, rgrn[:, 0], clsn_max))\n",
    "ds[\"ya_hat\"] = (\"sample\", np.where(clsn_max > 0, rgrn[:, 1], 0))\n",
    "\n",
    "lfig = ds.hvplot.hexbin(\n",
    "    x=\"y0\", y=\"y0_hat\", frame_width=300, aspect=1, logz=True, clabel=\"Count\", cmap=\"dimgray_r\",\n",
    "    title=f\"Training vs. Prediction (cut-off at {cut})\",\n",
    "    xlabel=\"True FGT(a=0)\", ylabel=\"Predicted FGT(a=0)\",\n",
    ") * hv.Slope(1, 0).opts(line_width=1, line_dash=\"dashed\", line_color=\"black\")\n",
    "\n",
    "rfig = ds.hvplot.hexbin(\n",
    "    x=\"ya\", y=\"ya_hat\", frame_width=300, aspect=1, logz=True, clabel=\"Count\", cmap=\"dimgray_r\",\n",
    "    title=f\"Training vs. Prediction (cut-off at {cut})\",\n",
    "    xlabel=\"True FGT(a=1)\", ylabel=\"Predicted FGT(a=1)\",\n",
    ") * hv.Slope(1, 0).opts(line_width=1, line_dash=\"dashed\", line_color=\"black\")\n",
    "\n",
    "(lfig + rfig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Value of Predictors**\n",
    "\n",
    "- \"Feature importance\" for ANN is not well-defined\n",
    "- Correlations suggest low quality predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = GetTrainingData()\n",
    "target = task.output()\n",
    "with target.open() as f:\n",
    "    ds = f.read()\n",
    "\n",
    "ds[\"location\"] = np.arange(ds.sizes[\"location\"])\n",
    "ds = ds.stack(sample=[\"period\", \"location\"]).dropna(\"sample\", subset=[\"y0\", \"ya\"])\n",
    "ds[\"sample\"] = np.arange(ds.sizes[\"sample\"])\n",
    "\n",
    "plt = ds.sel(source=\"fldas\", band=5, sample=slice(None, None, 10)).to_dataframe()\n",
    "lfig = plt.hvplot.hexbin(\n",
    "    y=\"y0\", x=\"x\", frame_width=300, aspect=1, cmap=\"dimgray_r\",\n",
    "    title=\"FGT by FEWSNet-FLDAS::SoilMoi10_40cm_tavg\", xlabel=\"z-score\", ylabel=\"FGT(a=0)\", logz=True)\n",
    "\n",
    "plt = ds.sel(source=\"esacci\", sample=slice(None, None, 10))\n",
    "pca = PCA(1)\n",
    "pca.fit(plt[\"x\"].data.transpose())\n",
    "plt[\"s\"] = (\"sample\", pca.transform(plt[\"x\"].data.transpose())[:, 0])\n",
    "plt = plt.drop_dims(\"band\")\n",
    "rfig = plt.hvplot.hexbin(\n",
    "    y=\"y0\", x=\"s\", frame_width=300, aspect=1, title=\"FGT by Landcover\",\n",
    "    ylabel=\"FGT(a=0)\", xlabel=\"PC-1 Score\", cmap=\"dimgray_r\", clabel=\"Count\", logz=True)\n",
    "\n",
    "lfig + rfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Conclusion: Model Development Pathways**\n",
    "\n",
    "- Training data:\n",
    "    - review accuracy of FGT calculation from survey data\n",
    "    - precise geolocation\n",
    "    - pool with LSMS or additional PSNP data\n",
    "- Predictors\n",
    "    - canvase additional gridded input\n",
    "    - higher resolution, Peter's drought indices\n",
    "- Model: ANN to LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### work-in-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.opts.defaults(hv.opts.Polygons(nonselection_alpha=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExplorePovertyModel(param.Parameterized):\n",
    "    \n",
    "    month = param.CalendarDate(\n",
    "        default=date(2016, 1, 1),\n",
    "        bounds=(date(2016, 1, 1), date(2018, 12, 1))\n",
    "    )\n",
    "\n",
    "    @pn.depends('month', watch=True)\n",
    "    def viz(self):\n",
    "        with open(\"output/poverty_format.json\", \"rb\") as f:\n",
    "            ds = xr.Dataset.from_dict(json.load(f))\n",
    "\n",
    "        data = ds.to_dataframe().reset_index()\n",
    "        # Drop admin3 data \n",
    "        data = data.drop(['admin3', 'W_CODE'], axis=1)\n",
    "        data = data.drop_duplicates()\n",
    "        \n",
    "        gdf = gpd.read_file(\"output/poverty_features.geojson\")\n",
    "        gdf = gdf.drop(['W_NAME', 'W_CODE', 'R_CODE'], axis=1)\n",
    "        gdf= gdf.dissolve(by='Z_CODE', as_index=False)\n",
    "        # Merge admin gdf and the poverty data\n",
    "        data = gdf.merge(data, on='Z_CODE')\n",
    "        data[\"Z_NAME\"] = data[\"Z_NAME\"].astype(str)\n",
    "        map_df = data.loc[data['period'] == self.month.strftime(\"%Y-%m\")].copy()\n",
    "        cty_plot = gv.Polygons(map_df, vdims=['admin2', 'Z_NAME']).opts(\n",
    "            tools=['hover', 'tap'], height=300, width=525,title=\"Average Difference from Poverty Line\"\n",
    "        )\n",
    "        map_plot = gts.OSM * cty_plot\n",
    "        selection_stream = hv.streams.Selection1D(source=cty_plot)\n",
    "        \n",
    "        def index_to_selection(index):\n",
    "            if len(index) == 0:\n",
    "                index = [0]\n",
    "            # FIXME: plot multiple zones\n",
    "            z_name = np.unique(cty_plot.iloc[index]['Z_NAME'])[0]\n",
    "            plot_df = data.loc[(data['Z_NAME'] == z_name)].copy()\n",
    "            # FIXME: Check the reason for duplicates\n",
    "            plot_df = plot_df.drop_duplicates(subset=['period', 'Z_NAME'])\n",
    "            return plot_df\n",
    "\n",
    "        def timeseries_callback(index):\n",
    "            plot_df = index_to_selection(index)\n",
    "            ts = hv.Dataset(plot_df[['period', 'admin2']]).to(hv.Curve, 'period' ,'admin2').opts(\n",
    "                opts.Curve(tools=['hover'], height=300, width=1000, show_grid=True, show_frame=False, xrotation=90, \n",
    "                           xlabel=\"Month\", ylabel='Difference from Poverty Line', show_legend=True))\n",
    "            return ts\n",
    "\n",
    "        ts_plot = hv.DynamicMap(timeseries_callback, streams=[selection_stream])\n",
    "        \n",
    "        out = pn.Column(map_plot.opts(width=700, height=400), ts_plot.opts(width=800))\n",
    "        return out\n",
    "    \n",
    "viewer = ExplorePovertyModel(name=\"Poverty Explore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = pn.Param(viewer.param,widgets={\"month\": pn.widgets.DatePicker}, width=200)\n",
    "pn.Row(params, viewer.viz).servable()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
